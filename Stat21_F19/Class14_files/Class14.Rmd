---
title: "Class 14"
subtitle: "STAT 021"
author: "Suzanne Thornton"
institute: "Swarthmore College"
date: "2019/10/2 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
 #   css: ["default", "assets/sydney-fonts.css", "assets/sydney.css"]
    self_contained: false # if true, fonts will be stored locally
#    includes:
 #     in_header: "assets/mathjax-equation-numbers.html"
    nature:
#      beforeInit: ["assets/remark-zoom.js", "https://platform.twitter.com/widgets.js"]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9' # alternatives '16:9' or '4:3' or others e.g. 13:9
      navigation:
        scroll: false # disable slide transitions by scrolling
---

```{r setup_pres, include=FALSE, echo=FALSE}
#devtools::install_github("ropenscilabs/icon")
#devtools::session_info('rmarkdown')

rm(list=ls())
library('tidyverse')
library('gridExtra')
library('broom')
library('cowplot')

library("RefManageR")
library("DT")


#setwd("~/Google Drive Swat/Swat docs/Stat 21/Class13_files")
#setwd("~/Drive/Swat docs/Stat 21/Class9_files")
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(fig.path='Figs/',echo=TRUE, warning=FALSE, message=FALSE)
hc_employer_2013 <- read_table2("health_care_2013_cleaned.txt", col_names = TRUE)
SLR_hc_employer_2013 <- lm(prop_coverage~spending_capita, data=hc_employer_2013)
SLR_hc2013_summary <- SLR_hc_employer_2013 %>% summary
```

```{css, echo=FALSE}
pre {
  background: #FFBB33;
  max-width: 100%;
  overflow-x: scroll;
}

.scroll-output {
  height: 75%;
  overflow-y: scroll;
}
   
.red{color: #ce151e;}
.green{color: #26b421;}
.blue{color: #426EF0;}
```



## Correction to Class 13 slides 
```{r unnamedClass14_1, echo=TRUE, eval=FALSE}
hc_employer_2013 <- read_table2("health_care_2013_cleaned.txt", col_names = TRUE)
CI_bounds <- as_tibble(predict(SLR_hc_employer_2013, hc_employer_2013,
                               interval="confidence", level = 0.95)) 
PI_bounds <- as_tibble(predict(SLR_hc_employer_2013, hc_employer_2013,
                               interval="predict", level = 0.95))
new_hc_data <- bind_cols(hc_employer_2013,CI_bounds,PI_bounds[,2:3]) %>%     
               as.tibble(.name_repair="universal")
## note the prediction interval bounds at the one's with "1" appended to the name

ggplot(new_hc_data, aes(x=spending_capita,y=prop_coverage)) + 
  ylim(0,1) + 
  geom_ribbon(aes(ymin=lwr1, ymax=upr1, fill='prediction'),alpha=0.3) +  
  geom_smooth(method="lm", se=TRUE, aes(fill='confidence'), alpha=0.3) +
  geom_point() +
  labs(title="Scatterplot of the data and the regression line",
       subtitle="Confidence and prediction intervals",
       y='Proportion of people covered',
       x='Per capita spending')
```


---
## Correction to Class 13 slides 
```{r unnamedClass14_2, echo=FALSE, fig.align='center'}
hc_employer_2013 <- read_table2("health_care_2013_cleaned.txt", col_names = TRUE)
CI_bounds <- as_tibble(predict(SLR_hc_employer_2013, hc_employer_2013,
                               interval="confidence", level = 0.95)) 
PI_bounds <- as_tibble(predict(SLR_hc_employer_2013, hc_employer_2013,
                               interval="predict", level = 0.95))
new_hc_data <- bind_cols(hc_employer_2013,CI_bounds,PI_bounds[,2:3]) %>%     
               as.tibble(.name_repair="universal")
## note the prediction interval bounds at the one's with "1" appended to the name

ggplot(new_hc_data, aes(x=spending_capita,y=prop_coverage)) + 
  ylim(0,1) + 
  geom_ribbon(aes(ymin=lwr1, ymax=upr1, fill='prediction'),alpha=0.3) +  
  geom_smooth(method="lm", se=TRUE, aes(fill='confidence'), alpha=0.3) +
  geom_point() +
  labs(title="Scatterplot of the data and the regression line",
       subtitle="Confidence and prediction intervals",
       y='Proportion of people covered',
       x='Per capita spending')
```



---
## Revisiting the meaning of the sums of squares terms
### In linear regression, what causes the response variable to vary?

In fitting our model we break the sources of variability in $y$ into two components:

  1) The variation in $x$ values. (deterministic) We measure this variation using the regression line by considering: $(\hat{y}_i – \bar{y} )$.

  2) Individual variation of $y$ about a line. (random) We measure this variation using the residuals: $y_i – \hat{y}_i$.


--
Thus the overall variability in $Y$ is the total of these two individual sources: 

  .center[Total variation in Y = variation due to x + variation NOT due to x]


Source    | Sums of sqs  | Deg of free. | Mean square | F-statistic
--------- | ------------ | ------------ | ----------- | ----------- 
Model     | $\sum_{i=1}^{n}(\hat{y}_i-\bar{y})^2$ | $1$   | $MSReg=\frac{SS_{reg}}{1}$ | $F=\frac{MSReg}{MSE}$
Residuals | $\sum_{i=1}^{n}(\hat{y}_i - y_i)^2$ | $n-2$ | $MSE=\frac{SSE}{n-2}$   | 

---
## Checking model assumptions

In SLR, we can plot residuals vs X or plot residuals vs predicted but it is better to get in the habit of plotting ** residuals vs predicted** because this is what we use in multiple linear regression.  


What are we looking for these plots? 

1. Any "trends" in the plot
  - E.g. negative residuals at small values of $\hat{y}_i$ and positive residuals at large values of $\hat{y}_i$ indicates non-linearity in the data. 
  - **Q:** What can we do to address non-linearity? 

1. Non-constant spread of the residuals
  - E.g. More clustered residuals for small $\hat{y}_i$ values and more spread out residuals for large $\hat{y}_i$, looks like "funneling". 
  

**Q:** What can we do to address heteroscedasticity? 
--
The usual remedy is a transformation of the response.


.footnote[<a href="https://data.princeton.edu/wws509/notes/c2s9
">Here</a> is my source for the interpretations above. This is helpful to check out tor further reading on regression diagnostics (although we are not covering all the material that is mentioned here).]


---
## Checking for normality 

Normal probability plots of the **residuals** help us check whether the combination of all the residuals is Normally distributed. 


Guide to interpreting QQ plots: 

  - If the data is curved, this indicates a skewed distribution

      - Downward concavity corresponds to negative Skewness (long tail to the left) 

      - Upward concavity indicating positive skewness. 

  - An S-shape indicates heavy tails, or an excess of extreme values, relative to the Normal distribution.






