<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Class 30</title>
    <meta charset="utf-8" />
    <meta name="author" content="Suzanne Thornton" />
    <link href="Class30_files/remark-css/default.css" rel="stylesheet" />
    <link href="Class30_files/remark-css/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Class 30
## STAT 021
### Suzanne Thornton
### Swarthmore College
### 2019/11/18 (updated: 2019-11-18)

---




&lt;style type="text/css"&gt;
pre {
  background: #FFBB33;
  max-width: 100%;
  overflow-x: scroll;
}

.scroll-output {
  height: 72%;
  overflow-y: scroll;
}

.scroll-small {
  height: 50%;
  overflow-y: scroll;
}

.pull-left {
  float: left;
  width: 47%;
}

.pull-right {
  float: right;
  width: 47%;
}
   
.red{color: #ce151e;}
.green{color: #26b421;}
.blue{color: #426EF0;}
&lt;/style&gt;

## Today's topics

- Quick review HW 7

- .blue[Estimation] practice problems

- .red[Inference] with MLR models

 
&lt;img src="Figs/dogbert.png" width="868" height="300" style="display: block; margin: auto;" /&gt;






---
## Wine data example

Previously, we modeled wine quality as a linear function of three predictor variables: (1) the degree of ionization of anthocyanins, (2) the pH level, (3) the type of wine and discussed the performance of several different MLRs. 

- Response variable - `\(y\)`, wine quality from 0-20

- Predictor variable - `\(w\)` (type), dummy variable for wine type, categorical (0=Cabernet Sauvignon, 1=Shiraz)

- Predictor variable - `\(x_2\)`, pH level, numerical (0-14, 7 being neutral)

- Predictor variable - `\(x_9\)`, percent of ionization, numerical (0-100 %)


Thus far, before today, we have only been looking at .blue[estimation] and .blue[prediction] with MLRs. Today we are going to talk about .red[inference] problems. 

---
## .red[Inference] 
### Wine example 

Recall the assumptions needed to for estimation and prediction: 

[1.] `\(E[\epsilon]=0\)`

[2.] `\(Var[\epsilon]= \sigma^2\)`

[3.] All `\(\epsilon\)` are independent of each other  


So far we've been able to check all threse of these assumptions and draw some conclusions about model fit and estimated effects on wine quality. 

Now if we want to draw conclusions *with certainty* we need to check that the fourth distributional assumption holds: 

[4.] `\(\epsilon\)` are all Gaussian random variables

---
## Checking the Gaussian assumption 
### QQ plots 

.pull-left[
&lt;img src="Figs/class29QQ1B-1.png" width="400" /&gt;
]

---
## Checking the Gaussian assumption 
### QQ plots 

.push-right[
&lt;img src="Figs/class29QQ2B-1.png" width="400" /&gt;
]

---
## Comparing two models 
### Hypothesis tests 

We can also do a test for the model fit with the overall F test. Note, unless we are comparing may (say &gt;20) different models, multiple testing is less likely to be a problem here. 

.scroll-small[

```r
MLR_wine1_standard_sum
```

```
## 
## Call:
## lm(formula = y ~ type + x2 + x9, data = wine_standard)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.95106 -0.87204 -0.03482  0.80278  2.98568 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  15.4059     0.2256  68.274  &lt; 2e-16 ***
## type.L       -0.6322     0.3245  -1.948   0.0615 .  
## x2            0.5096     0.2284   2.231   0.0339 *  
## x9            1.1913     0.2307   5.165 1.77e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.266 on 28 degrees of freedom
## Multiple R-squared:  0.5382,	Adjusted R-squared:  0.4887 
## F-statistic: 10.88 on 3 and 28 DF,  p-value: 6.552e-05
```

```r
MLR_wine4_standard_sum
```

```
## 
## Call:
## lm(formula = y ~ type + x2 + x9 + type * x9, data = wine_standard)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.08524 -0.93476 -0.07869  0.82660  3.02165 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  15.4648     0.2225  69.520  &lt; 2e-16 ***
## type.L       -0.6427     0.3156  -2.036   0.0516 .  
## x2            0.5318     0.2226   2.389   0.0241 *  
## x9            1.2038     0.2244   5.363 1.15e-05 ***
## type.L:x9    -0.5132     0.3178  -1.615   0.1180    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.231 on 27 degrees of freedom
## Multiple R-squared:  0.5789,	Adjusted R-squared:  0.5165 
## F-statistic: 9.279 on 4 and 27 DF,  p-value: 7.491e-05
```
]


---
## Comparing two models 
### Hypothesis tests 

Since the p-values from the overall F tests are both basically zero, I think the interaction model is the better of the two since it seems to satisfy our assumptions about the random error:

  - constant variance and
  
  - Gaussian distribution.


---
## Comparing two models 
### Hypothesis tests 

Now we can continue to dig into inferential problems such as the "significance" of the effects of each different predicor based on the individual t test output. But for this, we do need to be careful of possible multiple testing problems. 

.scroll-small[

```r
MLR_wine4_standard_sum$coefficients[,3:4]
```

```
##               t value     Pr(&gt;|t|)
## (Intercept) 69.519707 5.460064e-32
## type.L      -2.036319 5.163586e-02
## x2           2.389356 2.412661e-02
## x9           5.363486 1.148603e-05
## type.L:x9   -1.614891 1.179614e-01
```
]



---
## Intervals 
### Prediction and confidence

Finally, making sure that the Gaussian distribution assumption holds for our model, allows us to create confidence intervals for the mean response and/or prediction intervals for a new observation. 



Confidence intervals of the **average response** 
`$$\hat{y} \pm t_{\alpha/2, n-2}SE(\hat{y})$$`
where `\(SE(\hat{y}) = \sum_{i=1}^{n}(y_i - \bar{y})(x_i - \bar{x})\sqrt{\frac{1}{n} + \frac{(x_{new}-\bar{x})^2}{\sum_{i=1}^{n}(x_i-\bar{x})^2}}\)`

Prediction intervals of the **predicted response**
`$$\hat{y}_{new} \pm t_{\alpha/2, n-2}SE(\hat{y}_{new})$$`
where `\(SE(\hat{y}_{new}) = \sum_{i=1}^{n}(y_i - \bar{y})(x_i - \bar{x})\sqrt{1 + \frac{1}{n} + \frac{(x_{new}-\bar{x})^2}{\sum_{i=1}^{n}(x_i-\bar{x})^2}}\)`


---
## Intervals 
### Prediction and confidence

The prediction interval is designed to cover a “moving target”, the random future value of `\(y\)`, while the confidence interval is designed to cover the “fixed target”, the average (expected) value of `\(Y\)`, `\(E(Y)\)`.


.footnote[See Class 13 notes for additional resources on understanding CIs and PIs.]


---
## Confidence intervals and prediction intervals in R 
### Main effects model 


```r
new_wine_data_point = tibble(type = as.factor(1), x2 = as.double(9.1), x9 = as.double(85)) 
  
## Note we are using the models fit to the data including units
predict(MLR_wine1, new_wine_data_point, interval="confidence", level = 0.95) 
```

```
##        fit      lwr      upr
## 1 51.82935 30.39603 73.26268
```

```r
predict(MLR_wine1, new_wine_data_point, interval="predict", level = 0.95) 
```

```
##        fit      lwr      upr
## 1 51.82935 30.23969 73.41902
```


---
## Confidence intervals and prediction intervals in R 
### Main effects model 
.scroll-output[

```r
CI_bounds &lt;- as_tibble(predict(MLR_wine1, wine, interval="confidence", level = 0.95)) 
CI_bounds
```

```
## # A tibble: 32 x 3
##      fit   lwr   upr
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1  16.9  16.1  17.8
##  2  16.9  15.9  17.9
##  3  16.9  16.0  17.7
##  4  17.6  16.6  18.6
##  5  16.0  15.1  17.0
##  6  17.2  16.3  18.0
##  7  15.6  14.8  16.4
##  8  16.1  15.1  17.2
##  9  15.1  14.3  16.0
## 10  13.1  11.4  14.7
## # … with 22 more rows
```

```r
PI_bounds &lt;- as_tibble(predict(MLR_wine1, wine, interval="predict", level = 0.95))
PI_bounds 
```

```
## # A tibble: 32 x 3
##      fit   lwr   upr
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1  16.9  14.2  19.7
##  2  16.9  14.1  19.6
##  3  16.9  14.1  19.6
##  4  17.6  14.8  20.4
##  5  16.0  13.3  18.8
##  6  17.2  14.4  19.9
##  7  15.6  12.9  18.3
##  8  16.1  13.4  18.9
##  9  15.1  12.4  17.8
## 10  13.1  10.0  16.1
## # … with 22 more rows
```
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
