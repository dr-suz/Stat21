<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Class 34</title>
    <meta charset="utf-8" />
    <meta name="author" content="Suzanne Thornton" />
    <link href="Class34_files/remark-css/default.css" rel="stylesheet" />
    <link href="Class34_files/remark-css/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Class 34
## STAT 021
### Suzanne Thornton
### Swarthmore College
### 2019/12/4 (updated: 2019-12-09)

---




&lt;style type="text/css"&gt;
pre {
  background: #FFBB33;
  max-width: 100%;
  overflow-x: scroll;
}

.scroll-output {
  height: 75%;
  overflow-y: scroll;
}

.scroll-small {
  height: 50%;
  overflow-y: scroll;
}
   
.red{color: #ce151e;}
.green{color: #26b421;}
.blue{color: #426EF0;}
&lt;/style&gt;

 
&lt;img src="Figs/data_science_hire.jpg" height="500" style="display: block; margin: auto;" /&gt;





.footnote[https://www.kdnuggets.com/2012/06/data-science-cartoon.html]
  
  
---
## Variable selection methods
### Tukey's pairwise comparisons 

To determine if the different levels of a categorical variable are significantly different with respect to the response variable, we can use Tukey's Honest Significant Difference (Tukey's HSD)

`$$y_{ij}= \mu_i + \epsilon_{ij}$$`
for `\(j=1,\dots,n_i\)` and `\(i=1,\dots,k\)`

Tukey HSD tests all possible differences: `\(H_0:\)` `\(\mu_{i_1} = \mu_{i_2}\)`, for all `\(i_1 \neq i_2\)` in `\(i=1,\dots,k\)`.


---
## Variable selection methods
### Tukey's pairwise comparisons 

It can be confusing and even seemingly paradoxical to try to understand the output of Tukey's pairwise comparisons. What you have to keep in mind is that in statistical hypothesis tests, you never *accept the null hypothesis*, instead you "fail to reject"" it.


  - Since this is a test for a difference in means it doesn't apply if you are including an interaction term for a categorical and numerical predictor variable in your model. 
  
  - Tukey's HSD is basically just a t-test for the difference in means; but it's modified to take into account doing multiple tests on the same data set; 
  
  - This method only works if the sample sizes are about the same across each group (alternate methods exist). 



---
## Variable selection methods

**Tukey pairwise comparisons for levels of categorical variables**

.scroll-output[

```r
msleep2 &lt;- msleep %&gt;% filter(order == "Afrosoricida" |
                             order == "Artiodactyla" |
                             order == "Carnivora" ) %&gt;% 
           mutate(order_cat = fct_infreq(order)) %&gt;%
           select(order_cat, sleep_total)
SLR_msleep &lt;- lm(sleep_total ~ order_cat, data=msleep2)
aov_msleep &lt;- aov(sleep_total ~ order_cat, data=msleep2)
msleep_tukey &lt;- TukeyHSD(aov_msleep, conf.level=0.95)
msleep_tukey
```

```
##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = sleep_total ~ order_cat, data = msleep2)
## 
## $order_cat
##                                diff       lwr       upr     p adj
## Artiodactyla-Carnivora    -5.600000 -9.761471 -1.438529 0.0083367
## Afrosoricida-Carnivora     5.483333 -3.179459 14.146126 0.2608805
## Afrosoricida-Artiodactyla 11.083333  2.093528 20.073138 0.0151393
```

```r
library(multcomp)
summary(glht(aov_msleep, linfct = mcp(order_cat = "Tukey")))
```

```
## 
## 	 Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: aov(formula = sleep_total ~ order_cat, data = msleep2)
## 
## Linear Hypotheses:
##                                  Estimate Std. Error t value Pr(&gt;|t|)   
## Artiodactyla - Carnivora == 0      -5.600      1.613  -3.472  0.00765 **
## Afrosoricida - Carnivora == 0       5.483      3.357   1.633  0.24858   
## Afrosoricida - Artiodactyla == 0   11.083      3.484   3.181  0.01377 * 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## (Adjusted p values reported -- single-step method)
```
]


---
## Variable selection methods
### Tukey pairwise comparisons for levels of categorical variables

**Interpretation:** Do the Tukey HSD CIs contain zero? 

  - If so, then we do not have enough evidence to indicate that the average sleeping time for these two orders is significantly different. 
  
  - If not, then we can conclude that there is a statistically significant difference in the average sleeping time between the two orders. 


---
## Variable selection methods

**Tukey pairwise comparisons for levels of categorical variables**

.scroll-output[

```r
plot(TukeyHSD(aov_msleep, conf.level=0.95))
```

&lt;img src="Figs/tukeyHSDplot-1.png" style="display: block; margin: auto;" /&gt;
]

---
## Variable selection methods

**Tukey pairwise comparisons for levels of categorical variables**
.scroll-output[

```r
Tm2 &lt;- glht(aov_msleep, linfct = mcp(order_cat = "Tukey"))
plot(Tm2)
```

&lt;img src="Figs/tukeyHSDplot2-1.png" style="display: block; margin: auto;" /&gt;
]


---
## General good practices

  - Look carefully at residual plots to verify if the required assumptions are reasonable given the observed data. 

  - It's practically always more useful to report an actual p-value or confidence interval than just reporting an "accept/reject" decision.

  - If the units of measurement are practically meaningful, then try to use unstandardized measures rather than standardized measures. 

  - "Accepting the null hypothesis" is not a valid conclusion of a hypothesis test. 

  - Always provide some effect size estimate (in useful units) when reporting a p value. 

 &gt; "There is no substitute for graphical analysis of assumptions."[4]



---
## General good practices (continued)

If a study design is not a carefully randomized design, avoid inferring causality from your results. ("Even in randomized experiments, attributing causal effects to any one aspect of the treatment condition requires support from additional experimentation.")


If you are construing a randomized design you must explain the logic behind which predictors are included and explore rival hypotheses that might explain otherwise explain your results. 


When interpreting model effects, consider: credibility, generalizability, and robustness. 

  - Are the effects credible, given the results of previous studies and theory? 

  - Do things like the sample quality, the similarity of the study design to designs of previous studies, the similarity of the effects to those in previous studies suggest that your results are *generalizable*? 
  
  - Are the design and analytic methods robust enough to support strong conclusions?

---
## Variable selection methods
### Avoid these methods

**Stepwise regression**

Although this method is popular, easy to understand, and commonly taught in a first course in regression, it preforms very poorly and is not recommended. Generally, you're better off thinking about the problem and the data itself to select predictors than to blindly apply a streetwise selection criteria. 



**Individual t-tests**

Try to avoid making decisions about whether or not to include predictors in a model based on the individual tests for the "statistical significance" of each parameter's coefficient. Instead, consider the performance of the model overall. 



---
## References

[1] https://www.analyticsvidhya.com/blog/2016/03/practical-guide-principal-component-analysis-python/


[2] https://www.stat.cmu.edu/~cshalizi/mreg/15/lectures/21/lecture-21.pdf


[3] http://onlinestatbook.com/2/tests_of_means/pairwise.html


[4] Statistical Methods in Psychology Journals: Guidelines and Explanation by Leland Wilkinson and the Task Force on Statistical Inference. (1999) American Psychological Association. 54:8.


https://www.apa.org/pubs/journals/releases/amp-54-8-594.pdf


[CW: mentions of child sexual abuse and treats gender as a binary variable]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
