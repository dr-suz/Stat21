<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Class 5</title>
    <meta charset="utf-8" />
    <meta name="author" content="Suzanne Thornton" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Class 5
## STAT 021
### Suzanne Thornton
### Swarthmore College
### 2019/9/11 (updated: 2019-09-11)

---




&lt;style type="text/css"&gt;
pre {
  background: #FFBB33;
  max-width: 100%;
  overflow-x: scroll;
}
&lt;/style&gt;




&lt;img src="Figs/unreachable_state.png" style="display: block; margin: auto;" /&gt;

.footnote[Source: https://xkcd.com/2200/]

---

# Topics covered in today's lecture

  - Answering statistical questions about the body temperature data
  - Determining normality with Quantile-Quantile (QQ) plots


---
# Body temperature dataset


```
## # A tibble: 6 x 3
##   Temperature Handedness HeartRate
##         &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;
## 1        96.3 1                 70
## 2        96.7 1                 71
## 3        96.9 1                 74
## 4        97   1                 80
## 5        97.1 1                 73
## 6        97.1 1                 75
```

---
# Useful ways to manipulate data&lt;sup&gt;1&lt;/sup&gt;

Commonly used data manipulation functions
  - *select()*
  - *filter()*
  - *mutate()*
  - *group_by()*
  - *summarize()*
  - *count()* 

  
.footnote[1 https://datacarpentry.org/R-ecology-lesson/03-dplyr.html#selecting_columns_and_filtering_rows]  

---
# Visualizing data in R with *ggplot2*

Does the data look normally distributed? 



```r
body_temp_plot &lt;- ggplot(data=body_temp_dat, aes(Temperature)) 
                         
p1 &lt;- body_temp_plot + geom_histogram()  
p2 &lt;- body_temp_plot + geom_density()

#install.packages("cowplot") ##requires R version &gt;= 3.5.0  
library("cowplot")
plot_grid(p1, p2, align = "h", nrow = 1, rel_widths = c(1/2, 1/2))
```

&lt;img src="Figs/figDensity-1.png" style="display: block; margin: auto;" /&gt;


---
# The most useful statistical summaries 

Measure of "location"
  
  - Mean: sometimes this does not exist! 
  
  - Median
  
  - Mode
  
  - Plots! 
  
Measures of "spread" (or "scale") 
  
  - Standard deviation: sometimes this is infinite! (e.g. Cauchy distribution)
  
  - Interquartile range
  
  - Minimum and maximum
  
  - Plots! 


---

# Variance and standard deviation 

  - Standard deviation is a *standard* unit of measurement for Statisticians. Always specify, the standard deviation *of what?*. Otherwise, we have no idea what kind of data we are studying since standard deviation is unit-less! 

  - Variance is just a function of standard deviation. The same rules apply.

  - Standard error is a related concept; it is the standard deviation of the **estimate** for the parameter of interest.&lt;sup&gt;[1]&lt;/sup&gt; 

--


Standard error gives us a measurement of uncertainty about a parameter and thus is used in constructing confidence intervals for that parameter. 

Standard deviation on the other hand is a property of the data. 


.footnote[[1] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3148365/
]


---
# Analyze body temp data

  Is the true population mean really 98.6 degrees F? 
  

```r
body_temp_plot + geom_density() + 
                 geom_vline(xintercept=98.6, col="red")
```

&lt;img src="Figs/figDensity2-1.png" style="display: block; margin: auto;" /&gt;




---
# Analyze body temp data

For fun: what does a Cauchy density (green) look like in comparison to the data (black) or to a normal density (blue)? (Remember the Cauchy distribution has no finite mean or standard deviation.) 

&lt;img src="Figs/figDensity3-1.png" style="display: block; margin: auto;" /&gt;


---
# Analyze body temp data

At what temperature should we consider someone's temperature to be "abnormal"? 
--


To answer this question, we need a measurement of deviation for the temperature data. 


```r
sd(body_temp_dat$Temperature)
```

```
## [1] 0.7331832
```

```r
var(body_temp_dat$Temperature)
```

```
## [1] 0.5375575
```

---
# Analyze body temp data

What if we look at body temperature in degrees Celsius? 


```r
body_temp_dat2 &lt;- body_temp_dat %&gt;% 
                      mutate(CelciusTemp = ((Temperature-32)*5)/9)

sd(body_temp_dat2$CelciusTemp)
```

```
## [1] 0.407324
```

```r
var(body_temp_dat2$CelciusTemp)
```

```
## [1] 0.1659128
```

--
What we see here is that measurements of spread (standard deviation and variance) **depend** on the units of the data. 


---
# Analyze body temp data

How could I make it so that these values would **not change** depending on the units of my data? 


To *standardize* data points, take the original data set 
`$$x_{obs} = (x_{1}, x_{2}, \dots, x_{n}),$$`
and subtract the mean and divide by the sample standard deviation to get **unitless** data points

`$$z_{obs} = \left(\frac{x_{1}-\bar{x}}{s},\frac{x_{2}-\bar{x}}{s}, \dots, \frac{x_{n}-\bar{x}}{s}  \right).$$`
Let's prove this!    
   
---
# Analyze body temp data


In R, we create two new columns for the *standardized* Celsius and Fahrenheit temperatures and see that they are the same now because the data is unit-less! 


```r
body_temp_dat3 &lt;- body_temp_dat2 %&gt;% 
                      mutate(StandardizedTempFah = ((Temperature-mean(Temperature))/sd(Temperature)),
                             StandardizedTempCel = ((CelciusTemp-mean(CelciusTemp))/sd(CelciusTemp)))

print(body_temp_dat3[1:6,5:6])
```

```
## # A tibble: 6 x 2
##   StandardizedTempFah StandardizedTempCel
##                 &lt;dbl&gt;               &lt;dbl&gt;
## 1               -2.66               -2.66
## 2               -2.11               -2.11
## 3               -1.84               -1.84
## 4               -1.70               -1.70
## 5               -1.57               -1.57
## 6               -1.57               -1.57
```
 

---
# Analyze body temp data

Is the true population mean really 98.6 degrees F? 
  

```r
    t.test(body_temp_dat$Temperature, alternative="two.sided", mu=98.6, conf.level=0.95)
```

```
## 
## 	One Sample t-test
## 
## data:  body_temp_dat$Temperature
## t = -5.4548, df = 129, p-value = 2.411e-07
## alternative hypothesis: true mean is not equal to 98.6
## 95 percent confidence interval:
##  98.12200 98.37646
## sample estimates:
## mean of x 
##  98.24923
```

  

---
# Analyze body temp data

What would be the conclusion of a hypothesis test on the temperature in degrees *Celcius*? That is, what is our conclusion to the question: is the true population mean really 37 degrees Celsius? 
  

```r
    t.test(body_temp_dat2$CelciusTemp, alternative="two.sided", mu=37, conf.level=0.95)
```

```
## 
## 	One Sample t-test
## 
## data:  body_temp_dat2$CelciusTemp
## t = -5.4548, df = 129, p-value = 2.411e-07
## alternative hypothesis: true mean is not equal to 37
## 95 percent confidence interval:
##  36.73445 36.87581
## sample estimates:
## mean of x 
##  36.80513
```
  
---
# Analyze body temp data

Comparing the output of each of these t-tests for body temperature in Fahrenheit and Celsius we note the following:


.pull-left[
Things that **do not** depend on the unit of the data
  - t test statistic
  - degrees of freedom
  - critical t-value
  - p-value.]

.pull-right[Things that **do** depend on the units 
  - confidence interval 
  - null hypothesis value
  - sample estimates (mean and standard deviation).]

    
---
# Analyze body temp data
    
Is there a significant difference in average body temperature based on whether or not a person is right handed? 


```r
body_temp_dat_hand1 &lt;- body_temp_dat %&gt;% filter(Handedness==1) 
body_temp_dat_hand2 &lt;- body_temp_dat %&gt;% filter(Handedness==2) 

t.test(x=body_temp_dat_hand1$Temperature, y=body_temp_dat_hand2$Temperature, 
       alternative="two.sided", paired=FALSE, mu=0, conf.level=0.95)
```

```
## 
## 	Welch Two Sample t-test
## 
## data:  body_temp_dat_hand1$Temperature and body_temp_dat_hand2$Temperature
## t = -2.2854, df = 127.51, p-value = 0.02394
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.53964856 -0.03881298
## sample estimates:
## mean of x mean of y 
##  98.10462  98.39385
```

---
# Analyze body temp data
    
Is there a significant difference in average body temperature based on whether or not a person is right handed? 


```
## 
## 	Welch Two Sample t-test
## 
## data:  body_temp_dat_hand1$Temperature and body_temp_dat_hand2$Temperature
## t = -2.2854, df = 127.51, p-value = 0.02394
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.53964856 -0.03881298
## sample estimates:
## mean of x mean of y 
##  98.10462  98.39385
```
Question: Why aren't we using a paired t-test? 

--

Another question: What would our p-value be if we conducted this same test of the difference of means on the data set with temperature recorded in Celsius instead?


---
# Analyze body temp data

Is there a relationship between body temperature and heart rate? 


```r
body_temp_plot &lt;- ggplot(data=body_temp_dat, aes(x=Temperature, y=HeartRate)) +
  geom_point()
body_temp_plot                        
```

&lt;img src="Figs/figScatterplot-1.png" style="display: block; margin: auto;" /&gt;

--
This is the kind of question we will be investigating in this class. To do this, we need to understand how to build statistical models.... 


---
# A review of important statistical concepts

Suppose we observe `\(n\)` data points and, for each data point, we collect two measurements, one for variable `\(X\)` (e.g. age) and another for variable `\(Y\)` (e.g height). 

&lt;ol start="1"&gt;

&lt;li&gt; Expectation, variance, covariance&lt;/li&gt;&lt;/ol&gt;

`$$E[X] \approx \frac{1}{n}\sum_{i=1}^{n} x_{i}$$`
---
# A review of important statistical concepts

Suppose we observe `\(n\)` data points and, for each data point, we collect two measurements, one for variable `\(X\)` (e.g. age) and another for variable `\(Y\)` (e.g height). 

&lt;ol start="1"&gt;

&lt;li&gt; Expectation, variance, covariance&lt;/li&gt;&lt;/ol&gt;
`$$Var[X] = Cov[X, X] = E[(X-E[X])^2] = \dots = (E[X])^2 - E[X^2]$$` 
`$$\approx \frac{1}{n-1}\sum_{i=1}^{n}\left(x_{i}-\frac{1}{n}\sum_{i=1}^{n}x_{i}\right)^2$$`
--
`$$Cov[X, Y] = E[(X-E[X])(Y-E[Y])] = \dots = E[XY] - E[X]E[Y]$$` 
`$$\approx   \frac{1}{n-1}\sum_{i=1}^{n}\left(x_{i}-\frac{1}{n}\sum_{i=1}^{n}x_{i}\right)\left(y_{i}-\frac{1}{n}\sum_{i=1}^{n}y_{i}\right)$$`

---
# A review of important statistical concepts

Suppose we observe `\(n\)` data points and, for each data point, we collect two measurements, one for variable `\(X\)` (e.g. age) and another for variable `\(Y\)` (e.g height). 

&lt;ol start="2"&gt;
&lt;li&gt;Independence and Correlation&lt;/li&gt;&lt;/ol&gt;

Correlation is a standardized version of covariance: 

`$$\rho(X,Y) = Corr(X,Y) = \frac{Cov[X,Y]}{\sqrt{Var[X]Var[Y]}}.$$`

--      

If two RVs are independent, then they are uncorrelated. NOT vice versa! If `\(X\)` is independent of `\(Y\)` then `\(E[XY] = E[X]E[Y]\)` and thus `\(Cov[X, Y] = 0\)` and subsequently `\(Corr[X,Y] = 0\)`. 



---
# A review of important statistical concepts

Suppose we observe `\(n\)` data points and, for each data point, we collect two measurements, one for variable `\(X\)` (e.g. age) and another for variable `\(Y\)` (e.g height). 


&lt;ol start="3"&gt;
&lt;li&gt;Null hypothesis, test statistic, Type I and Type II errors&lt;/li&gt;
  &lt;ul&gt;&lt;li&gt;Boy who cried wolf story&lt;/li&gt;&lt;/ul&gt;

&lt;li&gt;Connection between confidence intervals and hypothesis tests&lt;/li&gt;&lt;/ol&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
