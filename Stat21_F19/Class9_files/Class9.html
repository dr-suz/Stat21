<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Class 9</title>
    <meta charset="utf-8" />
    <meta name="author" content="Suzanne Thornton" />
    <link href="Class9_files/remark-css/default.css" rel="stylesheet" />
    <link href="Class9_files/remark-css/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Class 9
## STAT 021
### Suzanne Thornton
### Swarthmore College
### 2019/9/20 (updated: 2019-09-22)

---




&lt;style type="text/css"&gt;
pre {
  background: #FFBB33;
  max-width: 100%;
  overflow-x: scroll;
}

.scroll-output {
  height: 80%;
  overflow-y: scroll;
}
   
.red{color: #ce151e;}
.green{color: #26b421;}
.blue{color: #426EF0;}
&lt;/style&gt;


&lt;img src="Figs/ten_thousand.png" width="600" style="display: block; margin: auto;" /&gt;

.footnote[https://xkcd.com/1053/]

---
## Important dates

- October 4th exam 1

  - Office hours that week: M 2-3:30pm and Tu 2-3:30pm (I will be traveling starting Wednesday after class - still available via email and Piazza)

- November 22nd exam 2
  
- December 13th final project due  

---
## For Exam 1: 
  
  - Some simple ANOVA problems 
  
  - All review material and all SLR material
  
  - No formula sheet or calculated will be needed
  
  - Review class on Wednesday, Oct 2nd 
  
  - New regualr office hours on W and Th (instead of M and Th)
  
--
## Outline for the next two classes: 

**Today**

  - .blue[Estimation] with simple linear regression models
  
**Next class**

  - .blue[Inference] with simple linear regression models

    
  
---
## Health care data 
.scroll-output[

```r
hc_employer_2013 &lt;- read_table2("health_care_2013_cleaned.txt", col_names = TRUE)
names(hc_employer_2013)
```

```
## [1] "Location"        "prop_coverage"   "spending_capita"
```

```r
class(hc_employer_2013)
```

```
## [1] "spec_tbl_df" "tbl_df"      "tbl"         "data.frame"
```

```r
dim(hc_employer_2013)
```

```
## [1] 51  3
```

```r
head(hc_employer_2013)
```

```
## # A tibble: 6 x 3
##   Location   prop_coverage spending_capita
##   &lt;chr&gt;              &lt;dbl&gt;           &lt;dbl&gt;
## 1 Alabama            0.446           33788
## 2 Alaska             0.520            7684
## 3 Arizona            0.437           41481
## 4 Arkansas           0.389           20500
## 5 California         0.465          278168
## 6 Colorado           0.538           34090
```
]

.green[Note that there are 51 "states" here (includes DC) - and not 52 like I was claiming earlier, duh!]


---
## Health care data 


```
## [1] "Location"        "prop_coverage"   "spending_capita"
```

```
## [1] "spec_tbl_df" "tbl_df"      "tbl"         "data.frame"
```

```
## [1] 51  3
```

```
## # A tibble: 6 x 3
##   Location   prop_coverage spending_capita
##   &lt;chr&gt;              &lt;dbl&gt;           &lt;dbl&gt;
## 1 Alabama            0.446           33788
## 2 Alaska             0.520            7684
## 3 Arizona            0.437           41481
## 4 Arkansas           0.389           20500
## 5 California         0.465          278168
## 6 Colorado           0.538           34090
```

(1) What are the observational units?


---
## Health care data 


```
## [1] "Location"        "prop_coverage"   "spending_capita"
```

```
## [1] "spec_tbl_df" "tbl_df"      "tbl"         "data.frame"
```

```
## [1] 51  3
```

```
## # A tibble: 6 x 3
##   Location   prop_coverage spending_capita
##   &lt;chr&gt;              &lt;dbl&gt;           &lt;dbl&gt;
## 1 Alabama            0.446           33788
## 2 Alaska             0.520            7684
## 3 Arizona            0.437           41481
## 4 Arkansas           0.389           20500
## 5 California         0.465          278168
## 6 Colorado           0.538           34090
```

(2) What are the variables in this study, what type of variables are they, and which roles do they each play?


---
## Health care data 


```
## [1] "Location"        "prop_coverage"   "spending_capita"
```

```
## [1] "spec_tbl_df" "tbl_df"      "tbl"         "data.frame"
```

```
## [1] 51  3
```

```
## # A tibble: 6 x 3
##   Location   prop_coverage spending_capita
##   &lt;chr&gt;              &lt;dbl&gt;           &lt;dbl&gt;
## 1 Alabama            0.446           33788
## 2 Alaska             0.520            7684
## 3 Arizona            0.437           41481
## 4 Arkansas           0.389           20500
## 5 California         0.465          278168
## 6 Colorado           0.538           34090
```

(3) Is the study observational or is it an experiment?


---
## Health care data 


```
## [1] "Location"        "prop_coverage"   "spending_capita"
```

```
## [1] "spec_tbl_df" "tbl_df"      "tbl"         "data.frame"
```

```
## [1] 51  3
```

```
## # A tibble: 6 x 3
##   Location   prop_coverage spending_capita
##   &lt;chr&gt;              &lt;dbl&gt;           &lt;dbl&gt;
## 1 Alabama            0.446           33788
## 2 Alaska             0.520            7684
## 3 Arizona            0.437           41481
## 4 Arkansas           0.389           20500
## 5 California         0.465          278168
## 6 Colorado           0.538           34090
```

(4) Does the study use random sampling, random assignment, both or neither?


---
## SLR for health care data 

&lt;img src="Figs/hcRegressionClass9-1.png" style="display: block; margin: auto;" /&gt;

--
.center[.red[This is different from a QQ plot!]]

---
## SLR for health care data 

.scroll-output[
We are .red[not] looking at a .red[QQ-line] over a scatterplot of the sample quantiles, rather, we are looking at a **regression line** over a scatterplot of the data. 



```r
SLR_hc_employer_2013 &lt;- lm(prop_coverage~spending_capita, data=hc_employer_2013)
summary(SLR_hc_employer_2013)
```

```
## 
## Call:
## lm(formula = prop_coverage ~ spending_capita, data = hc_employer_2013)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.12870 -0.04341  0.00710  0.03711  0.09344 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      5.137e-01  1.027e-02  50.030   &lt;2e-16 ***
## spending_capita -1.319e-07  1.446e-07  -0.912    0.366    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.05427 on 49 degrees of freedom
## Multiple R-squared:  0.01669,	Adjusted R-squared:  -0.003373 
## F-statistic: 0.8319 on 1 and 49 DF,  p-value: 0.3662
```
]

---
## Assumptions for estimation with SLR

`$$Y = \beta_0 + \beta_1 x + \epsilon$$`

1. `\(E[\epsilon]=0\)`;

1. `\(Var[\epsilon]=\sigma^2 &lt; \infty\)`;

1. Each instance of the random variable `\(\epsilon\)` is independant of any other instance. 


--
All of these assumptions have to do with the random variable `\(\epsilon\)`. We never actually observe any instances of `\(\epsilon\)`, the best thing we have are the observed residuals. (But note that these residuals treat our estimates of the model parameters (slope and intercept) as if they are definitely correct, in reality, this was just an informed guess.)

---
##Checking assumption 1:  zero mean

`$$E[\varepsilon]=0$$`


The mean of the residuals will always be zero because they are calculated based on the regression line we fit. 


```r
SLR_hc_employer_2013 %&gt;% 
  residuals %&gt;% 
  mean 
```

```
## [1] 6.453561e-19
```



---
##Checking assumption 1: zero mean

`$$E[\varepsilon]=0$$`


The mean of the residuals will always be zero because they are calculated based on the regression line we fit. 

&lt;img src="Figs/hcRegressionClass9_4-1.png" style="display: block; margin: auto;" /&gt;


- If you suspect that the mean of your `\(Y\)` measurement errors is non-zero, you can still ensure that this model assumption is met by **standardizing the data** before you fit a regression curve. 


- When we get to MLR (multiple linear regression), it will become more important to standardize the data before fitting a regression line. 

---
##Checking assumption 2: .red[constant] variance

`$$Var[\epsilon]=\sigma^2 &lt; \infty$$`

&lt;a href="https://en.wikipedia.org/wiki/Heteroscedasticity"&gt;Heteroscedasticity&lt;/a&gt; often occurs when there is a large difference among the sizes of the response variable. What we are looking for here is: does our measurement error `\((\epsilon)\)` vary (increase or decrease) with each new observation `\((y_i, x_i)\)`?

  - cross section data 
  - time series data 
  - econometrics data 


1. Example: Income versus money spent on meals.

1. Example: Measuring changing distance of a rocket being launched. 

.footnote[For more reading on heteroscedacity: http://www.statsmakemecry.com/smmctheblog/confusing-stats-terms-explained-heteroscedasticity-heteroske.html (note that they use the terms independent and dependent variables which is not great but common!)]
---
##Checking assumption 2: .red[constant] variance

`$$Var[\epsilon]=\sigma^2 &lt; \infty$$`

&lt;img src="Figs/hcRegressionHetero-1.png" style="display: block; margin: auto;" /&gt;
---
##Checking assumption 2: .red[constant] variance

So you have evidence of heteroskedasity, what now? 

--
It **is** ethical/permissible statistically to play around with transforming the data `\((x_i, y_i)\)`! So try transforming the response and/or predictor variable to address this problem. 


In general, for linear modeling, some heteroskedasity is not a deal-breaker, there are more severe consequences however for non-linear models (e.g. logit or probit models).


--
What do I mean by *severe consequences*?

---
##Checking assumption 3: independence

This assumption is difficult to check. Usually you have to think critically about what are potential sources of error in your measurements of the response variable `\(Y\)`.


For temporal data, you can check the &lt;a href=""&gt;autocorrelation&lt;/a&gt;.


Otherwise, we can look for linear relationships in scatter plots of the residuals and the predictor variables. If we find evidence of this, we may need to re-consider what predictor variables we include in our model. 

---
## &lt;a href="https://en.wikipedia.org/wiki/Central_limit_theorem#Classical_CLT"&gt;Central limit theorem&lt;/a&gt;

**English version:**

If: `\(X_1, X_2, \dots,X_n\)` are (1) all random variables with the same distribution (e.g. all Poisson, all beta, all t-distributed) and (2)there are no statistical dependencies between any two arbitrary groups of these random variables and (3)the average and variance of these random variables are all the same 


Then the distribution of the average of these `\(n\)` random variables is Gaussian with the same mean and variance as the individual random variables 


**Math version:**

If `\(X_1, X_2, \dots,X_n\)` are all random variables with the same distribution, if they are all independent of one another, and if `\(E[X_{i}]=\mu\)` and `\(Var[X_{i}]=\sigma^2\)` for all `\(i=1,\dots,n\)` then

`$$\bar{X} \sim N(\mu, \sigma).$$`
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
