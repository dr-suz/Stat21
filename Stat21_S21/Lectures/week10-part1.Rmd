---
title: "Week 10 - Part 1"
subtitle: "Simulation study about confidence intervals"
author: "Suzanne Thornton"
institute: "Swarthmore College"
date: "For class in Week 10 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
 #   css: ["default", "assets/sydney-fonts.css", "assets/sydney.css"]
    self_contained: false # if true, fonts will be stored locally
#    includes:
 #     in_header: "assets/mathjax-equation-numbers.html"
    nature:
#      beforeInit: ["assets/remark-zoom.js", "https://platform.twitter.com/widgets.js"]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9' # alternatives '16:9' or '4:3' or others e.g. 13:9
      navigation:
        scroll: false # disable slide transitions by scrolling
includes:
  in_header: mystyles.sty
---

```{r setup_pres, include=FALSE, echo=FALSE}
#devtools::install_github("ropenscilabs/icon")
#devtools::session_info('rmarkdown')
rm(list=ls())
library('tidyverse')
library('gridExtra')
library('broom')
library('cowplot')
library("RefManageR")
library("DT")

#setwd("~/Google Drive Swat/Swat docs/Stat 21/Class13_files")
#setwd("~/Drive/Swat docs/Stat 21/Class9_files")
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(fig.path='Figs/',echo=TRUE, warning=FALSE, message=FALSE)
```

```{css, echo=FALSE}
pre {
  background: #FFBB33;
  max-width: 100%;
  overflow-x: scroll;
}

.scroll-output {
  height: 70%;
  overflow-y: scroll;
}

.scroll-small {
  height: 50%;
  overflow-y: scroll;
}
   
.red{color: #ce151e;}
.green{color: #26b421;}
.blue{color: #426EF0;}
```


## Problem set-up

$$y = 50 + 10x + \epsilon, \quad \text{where } \epsilon \sim N(0,16)$$


Generate 500 samples of 20 observations drawing one observation for each level of $x=1,1.5,2, \dots,10$ for each sample. 

```{r}
set.seed(1001)  # this makes all our code results reproducible 
remove(list=ls())  # this makes sure we clear all previously defined environmental variables 
library('tidyverse')
x <- seq(0.5, 10, by=0.5) 

generate.response <- function(x){
  y <- 50 + 10*x + rnorm(20, mean=0, sd=4)
  return(y)
}
y_mtx <- matrix(rep(x, 500), ncol=500, byrow=FALSE)
y_mtx <- apply(y_mtx, 2, generate.response)
```



.footnote[This is based on Problem 2.23 of our textbook.] 

---
## Part 1
### For each sample compute the least-squares estimates of the slope and intercept.

.scroll-output[
```{r}
estimate.parameters <- function(response, predictor=x){
  mod = lm(response ~ predictor)
  beta0_hat = mod$coefficients[1]
  beta1_hat = mod$coefficients[2]
  return(c(beta0_hat, beta1_hat))
}

estimated_betas <- matrix(rep(NA,500*2), ncol=2)
colnames(estimated_betas) <- c("beta0_hat", "beta1_hat")
for(k in 1:500){
  estimated_betas[k,] = estimate.parameters(y_mtx[ ,k])
}

(estimated_betas <- data.frame(estimated_betas))
```
]

---
## Part 1
## Visualize the different sample estimates

The code on the next two slides constructs histograms of the sample vlaues of $\hat{\beta}_0$ and $\hat{\beta}_1$. 

**Question:** Why do these histograms appear to follow a Normal distribution? 


---
##  Part 1
### Visualize the different $\hat{\beta}_0$ values

.scroll-output[
```{r}
ggplot(estimated_betas, aes(x=beta0_hat)) + 
  geom_histogram(bins=40) + 
  labs(title= "Histogram of the estimated intercept for a SLR model", x = "beta0_hat values for each sample", y = "Density")
```
]


---
##  Part 1
### Visualize the different $\hat{\beta}_1$ values

.scroll-output[
```{r}
ggplot(estimated_betas, aes(x=beta1_hat)) + 
  geom_histogram(bins=40) + 
  labs(title= "Histogram of the estimated slope for a SLR model", x = "beta1_hat values for each sample", y = "Density")
```
]


---
## Part 2
### For each sample, compute an estimate of $E[Y \mid x=5]$. 

.scroll-output[
```{r}
estimate.observation <- function(response,predictor=x){
  mod <- lm(response ~ predictor)
  y_hat <- mod$coefficients[1] + mod$coefficients[2]*5
  return(y_hat=y_hat)
}

y_hats <- rep(NA,500)
for(k in 1:500){
  y_hats[k] = estimate.observation(y_mtx[ ,k])
}
(y_hats <- data.frame(y_hats))
```
]

---
## Part 2 
### Visualize the different $\hat{y} = E[Y \mid x=5]$ values

The code on the next slide constructs a histogram of the estimates you obtained (the 500 y_hat values). 

**Question:** What shape do you expect this distribution to look like and why? 

---
## Part 2 
### Visualize the different $\hat{y} = E[Y \mid x=5]$ values

.scroll-output[
```{r}
ggplot(y_hats, aes(x=y_hats)) + 
  geom_histogram(bins=40) + 
  labs(title= "Histogram of the fitted response for x=5", x = "Different y_hat values for each sample", y = "Density")
```
]

---
## Part 3 
### For each sample, compute a $95\%$ CI on the slope, $\beta_1$

First, let's write a function that will compute the lower and upper bound:

```{r}
CI.slope <- function(response,predictor=x){
  mod <- lm(response ~ predictor)
  t_crit <- qt(0.05/2, df=20-2, lower.tail=FALSE)
  se_beta1 <- summary(mod)$coefficients[2,2] ##?
  beta1_hat <- mod$coefficients[2]
  LB <- beta1_hat - t_crit*se_beta1
  UB <- beta1_hat + t_crit*se_beta1
  return(c(LB, UB))
}
```

---
## Part 3 
### For each sample, compute a $95\%$ CI on the slope, $\beta_1$

.scroll-output[
Now, let's apply the function `CI.slope` to our 500 random samples and look at all of the upper and lower bounds computed for each sample. 
```{r}
LB_slope <- rep(NA,500)
UB_slope <- rep(NA, 500)
for(k in 1:500){
  conf_int = CI.slope(y_mtx[ ,k])
  LB_slope[k] = conf_int[1]
  UB_slope[k] = conf_int[2]
}
cbind(LB_slope,UB_slope)
```
]

---
## Part 3 
### For each sample, compute a $95\%$ CI on the slope, $\beta_1$

**Question:** How many of these 500 intervals would you expect contain the true value of $\beta_1=10$? 

--
.scroll-small[
```{r}
((LB_slope<=10)&(UB_slope>=10))
```
]


---
## Part 3 
### For each sample, compute a $95\%$ CI on the slope, $\beta_1$

**Question:** How many of these 500 intervals would you expect contain the true value of $\beta_1=10$? 

```{r}
sum((LB_slope<=10)&(UB_slope>=10))
```


---
## Part 4 
### For each estimate of $E[Y \mid x=5]$ in part 2, compute the $95\%$ CI for the mean response

As before, let's write a function that will compute the lower and upper bound:

```{r}
CI.mean.response <- function(response,predictor=x){
  dat <- data.frame(response, predictor)
  remove(list=c("response","predictor"))
  mod <- lm(response ~ predictor, dat)
  y_hat <- data.frame(response = mod$coefficients[1] + mod$coefficients[2]*5, predictor=5)
  PI <- predict(mod, y_hat, interval="confidence", level = 0.95)
  return(c(PI[2], PI[3]))
}
```

---
## Part 4 
### For each estimate of $E[Y \mid x=5]$ in part 2, compute the $95\%$ CI for the mean response

.scroll-output[
Now, let's apply the function `CI.mean.response` to our 500 random samples and look at all of the upper and lower bounds computed for each sample. 

```{r}
LB_mean_response <- rep(NA,500)
UB_mean_response <- rep(NA, 500)
for(k in 1:500){
  conf_int = CI.mean.response(y_mtx[ ,k])
  LB_mean_response[k] = conf_int[1]
  UB_mean_response[k] = conf_int[2]
}
cbind(LB_mean_response,UB_mean_response)
```
]


---
## Part 4 
### For each estimate of $E[Y \mid x=5]$ in part 2, compute the $95\%$ CI for the mean response

**Question:** How many of these 500 intervals would you expect contain the true value of $E[Y \mid x=5]=100$? 

--
```{r}
sum((LB_mean_response<=100)&(UB_mean_response>=100))
```
