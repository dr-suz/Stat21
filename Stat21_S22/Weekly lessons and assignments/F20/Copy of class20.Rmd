---
title: "Class 20"
subtitle: "Statistical Methods II (Stat 021)"
author: "Suzanne Thornton"
institute: "Swarthmore College"
date: "For class on Thursday, April 22, 2021 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
 #   css: ["default", "assets/sydney-fonts.css", "assets/sydney.css"]
    self_contained: false # if true, fonts will be stored locally
#    includes:
 #     in_header: "assets/mathjax-equation-numbers.html"
    nature:
#      beforeInit: ["assets/remark-zoom.js", "https://platform.twitter.com/widgets.js"]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9' # alternatives '16:9' or '4:3' or others e.g. 13:9
      navigation:
        scroll: false # disable slide transitions by scrolling
includes:
  in_header: mystyles.sty
---

```{r setup_pres, include=FALSE, echo=FALSE}
#devtools::install_github("ropenscilabs/icon")
#devtools::session_info('rmarkdown')

rm(list=ls())
library('tidyverse')
library('gridExtra')
library('broom')
library('cowplot')
library("RefManageR")
library("DT")

#setwd("~/Google Drive Swat/Swat docs/Stat 21/Class13_files")
#setwd("~/Drive/Swat docs/Stat 21/Class9_files")
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(fig.path='Figs/',echo=TRUE, warning=FALSE, message=FALSE)
```

```{css, echo=FALSE}
pre {
  background: #FFBB33;
  max-width: 100%;
  overflow-x: scroll;
}

.scroll-output {
  height: 60%;
  overflow-y: scroll;
}

.scroll-small {
  height: 30%;
  overflow-y: scroll;
}
   
.red{color: #ce151e;}
.green{color: #26b421;}
.blue{color: #426EF0;}
```


# Agenda

Here's the agenda for today's class: 

- Group check-ins (5 mins)

- Go over questions from Test 2 (5 mins)

- Questions from comprehension quiz (10 mins)

- Detecting influential data points (10 mins)

- Homework 7 exercises (30 mins)

- Housekeeping items and announcements (5 mins)

---
# Thursday check-in 

- Send me a screenshot of your check-in markers on Slack

- [Fill out the group roles for today's class](https://docs.google.com/spreadsheets/d/1d34JxqXQON6MyIEjN5ugkByCeTuGTTb_ovvPfSAca_g/edit?usp=sharing) 

```{r, echo=FALSE, fig.align='center', out.height=500}
knitr::include_graphics("Figs/feelings_wheel.jpg")
```

---
## Test 2 
### (5 mins) 

Pause recording! 

---
## Comprehension quiz 
### Week 11  (10 mins) 

- Interpret the results of the MLR test - We will cover this again with today's material! 

- Question 5 - If we add a second predictor variable to a simple linear regression model, the sum of the squared residuals with either decrease or stay the same. Key concept: *overfitting*.

- Question 7 - What is extrapolation? Look at the boundaries of observed predictor variables. We will also cover this more with today's material! 

- Question 9 - There was a typo in the quiz solutions! I have fixed it this morning.  

- In general, what happens to R-squared when we add another predictor variable to our model?  


$$SSE = \sum_{i=1}^{n}(y_{obs,i} - \hat{y}_{i})^2$$

$$R^2 = \frac{SS_{reg}}{SS_{tot}} = 1 - \frac{SSE}{SS_{tot}}$$ 


---
## Multiple linear regression (MLR)

General model for $p$ predictor variables

$$Y \mid (x_1, x_2, \dots, x_p) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_p x_p + \epsilon$$

where the following assumptions are made about the random noise, $\epsilon$

  - $E(\epsilon)=0$ and more importantly, $Var(\epsilon)=\sigma^2$;
  
  - All errors are independent of one another; 
  
  - The error is normally distributed (only necessary for *inference*). 

---
## Residuals and MLR models 

- Residuals: $e_i = y_{obs,i}-\hat{y}_i$ 

- Standardized residuals: $r_i = \frac{e_i}{SE(e_i)} = \frac{e_i}{\sqrt{MSE(1-h_{ii})}}$

- Studentized/jackknifed residuals: $t_i = \frac{d_i}{SE(d_i)} = \frac{e_i}{MSE_{(i)}(1-h_{ii})}$ where 

  * $d_i = y_{obs,i} - \hat{y}_{(i)}$ with $\hat{y}_{(i)}$ denoting the fitted value for the $i$th data point based on the estimated model from the data set with the $i$th data point deleted  
  
  * Similarly $MSE_{(i)}$ is the $MSE$ from the estimated model based on the data set excluding the $i$th data point.  



---
## Identifying potentially influential data points 

  - Outliers: the observed value of the response is very different from the predicted value from the model 
  
    * Standardized residuals quantify how large the residuals are in standard deviation units, and therefore can be easily used to identify outliers.

    * Rule of thumb: An observation with a standardized residual that is larger than 3 (in absolute value) is deemed by some to be an outlier. 
    

  - Leverage points: the observed combination of the predictor values is highly unusual. This is related to the concept of extrapolation! 

      * $h_{ii}$ quantifies the influence that the observed response $y_{obs,i}$ has on its predicted value $\hat{y}_i$.
  
      * In other words, $h_{ii}$ quantifies how far away the $i$th $x$ value is from the rest of the $x$ values. 
  
      * $h_{ii}$ is a number between 0 and 1, inclusive. If the $i$th $x$ value is far away, $h_{ii}$ will be close to $1$; and otherwise it will be close to $0$.
      
      * Rule of thumb: investigate any observation whose leverage value is more than 3 times larger than the mean leverage value. 





---
## Coding in R 

Leverage 

```{r eval=FALSE}
mod %>% hatvalues 

leverage <- mod %>% hatvalues 
m <- leverage %>% length 
leverage_data <- data.frame(leverage = leverage, index = 1:m)

ggplot(leverage_data, aes(x=index, y=leverage)) + 
  geom_col() + 
  labs(main = "Leverage values", x = "Index", y = "Leverage")
```


Studentized residuals 

```{r eval=FALSE}
library("MASS")
mod %>% studres 
```



---
## Identifying potentially influential data points 

To evaluate whether or not candidate data points are *influential* with respect to our estimated regression model, there are different measures that use functions of the leverage points and residuals to establish more "rules of thumb"
  
  - Difference in fits (DFFITS)
  
  - Cook's distance 

You won't be tested on these measures but I want to at least be aware of their purpose and existance. 

---
## Dealing with influential data points  

.scroll-output[
First, check for obvious data errors:

  - If the error is just a data entry or data collection error, correct it.

  - If the data point is not representative of the intended study population, delete it.

  - If the data point is a procedural error and invalidates the measurement, delete it.

Consider the possibility that you might have just misformulated your regression model:

  - Did you leave out any important predictors?

  - Should you consider adding some interaction terms?

  - Is there any nonlinearity that needs to be modeled?

  - If nonlinearity is an issue, one possibility is to just reduce the scope of your model. If you do reduce the scope of your model, you should be sure to report it, so that readers do not misuse your model.

Decide whether or not deleting data points is warranted:

  - Do not delete data points just because they do not fit your preconceived regression model.
  
  - You must have a good, objective reason for deleting data points.

  - If you delete any data after you've collected it, justify and describe it in your reports.

  - If you are not sure what to do about a data point, analyze the data twice — once with and once without the data point — and report the results of both analyses.
]

**Always use your common sense and knowledge about the situation!**


This slide is copied from this [resource](https://online.stat.psu.edu/stat462/node/87/) which has a helpful chapter on detecting influential points in a MLR model. 


---
# Homework 7 
## Problems 1-2

The director of admissions of a small college selected 120 students at random from the new freshman class in a study to determine whether a student's grade point average (GPA) at the end of the freshman year $(Y)$ can be predicted from the ACT test score $(X_1)$ and from a binary categorical indicator of whether or not the student had chosen a major field of concentration at the time their application was submitted. The categorical predictor variable is coded so that 
$$X_2 = \begin{cases}0, \quad \text{if the major field was undecided} \\ 1, \quad  \text{if the student had indicated a major field of concentration at the time of application} \end{cases}.$$

.scroll-small[
```{r}
library("tidyverse")
admissions <- read.csv(url(
              "http://www.swarthmore.edu/NatSci/sthornt1/DataFiles/admissions_data.csv"))
head(admissions)
```
]


---
# Homework 7 


**Problem:** Explain the interpretation of each of the regression model coefficients within the context of this data:
$$Y_i \mid x_{1,i}, x_{2,i} = \beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i} + \epsilon_i,$$
where 
$$x_{2,i} = \begin{cases}0, \quad \text{if student i is undecided} \\ 1, \quad  \text{if student i indicated a major field of concentration at the time of application} \end{cases},$$
and $E(\epsilon_i)=0$, $Var(\epsilon_i) = \sigma^2$, and all the errors are independent. 


**Problem:** Fit the regression model from Problem 1 and state the estimated regression equation. 

```{r}
gpa_mod <- lm(GPA ~ ACT + factor(major), admissions)
```



```{r echo=FALSE, eval=FALSE}
leverage <- gpa_mod %>% hatvalues 
sum(leverage > 0.8)


m <- leverage %>% length 
leverage_data <- data.frame(leverage = leverage, index = 1:m)

ggplot(leverage_data, aes(x=index, y=leverage)) + 
  geom_col() + 
  labs(main = "Leverage values", x = "Index", y = "Leverage")
```

```{r eval=FALSE}
library("MASS")
gpa_mod %>% studres 
data_res <- admissions %>% mutate(stu_res = studres(gpa_mod),
                                  fit_y = gpa_mod$fitted.values)

ggplot(data_res, aes(x=fit_y, y=stu_res)) + 
  geom_point() + 
  labs(main = "Studentized residual plot", 
       x = "Fitted values", y="Studentized residuals")
```

---
# Homework 7 
## Group work (10 mins)

**Instructions:** With your group, answer the following problem based on the regression model from the previous slide. Hand in either a screenshot of your answers or the text for your answers to me in a group Slack message. Make sure to mark your progress in the [Group Progress Checker](https://docs.google.com/spreadsheets/d/1d34JxqXQON6MyIEjN5ugkByCeTuGTTb_ovvPfSAca_g/edit?usp=sharing). (Please do not call me into your Zoom breakout room but use this form instead!)


**Problem 1:** Is there any evidence of outliers or other potentially influential data points in this data set? What might be causing these points to look like outliers or to be leverage points? 


---
# Homework 7 

A hospital administrator wished to study the relation between patient satisfaction $(Y)$, and patient's age $(X_1, \text{ in years})$, severity of illness $(X_2, \text{ an index})$, and anxiety level $(X_3, \text{ an index})$. The administrator randomly selected $46$ patients and collected the data presented below, where larger values of $Y,$ $X_2$, and $X_3$ are, respectively, associated with more satisfaction, increased severity of illness, and more anxiety.  

.scroll-small[
```{r}
satisfaction <- read.csv(url("http://www.swarthmore.edu/NatSci/sthornt1/DataFiles/patient_satisfaction.csv"))
head(satisfaction)
```
]


---
# Homework 7 

.scroll-output[
Create a matrix scatter plot for all of the variables (predictor and response).  
```{r}
satisfaction %>% plot
```
]

---
# Homework 7 
## Group work (7 mins)

**Instructions:** Reference the code output on the next slide where we fit the regression model 
$$Y_i \mid x_{1,i}, x_{2,i}, x_{3,i} = \beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i} + \beta_3 x_{3,i} + \epsilon_i$$
assuming $E(\epsilon_i)=0$, $Var(\epsilon_i) = \sigma^2$, and all the errors are independent. Work with your group to answer the following problem. Hand in either a screenshot of your answers or the text for your answers to me in a group Slack message. Make sure to mark your progress in the [Group Progress Checker](https://docs.google.com/spreadsheets/d/1d34JxqXQON6MyIEjN5ugkByCeTuGTTb_ovvPfSAca_g/edit?usp=sharing).

**Problem 2:** Clearly write out the estimated regression equation. What is the interpretation of $\hat{\beta}_2$ in this model? 



---
# Homework 7 
## Group work 

.scroll-output[
```{r}
satisfaction_mod <- lm(satisfaction ~ age + severity + anxiety, satisfaction)
summary(satisfaction_mod)
```
]


---
# Homework 7 
## Group work (7 mins) 

**Instructions:** Suppose the assumption of independent Normally distributed errors is applicable to this data. With your group, use the following coding template to answer the problem below. The first line of code brings up the R help documentation on applying the `predict()` function to `lm()` objects and may be of help. Hand in either a screenshot of your answers or the text for your answers to me in a group Slack message. Make sure to mark your progress in the [Group Progress Checker](https://docs.google.com/spreadsheets/d/1d34JxqXQON6MyIEjN5ugkByCeTuGTTb_ovvPfSAca_g/edit?usp=sharing).

**Problem 3:** Obtain a $90\%$ interval estimate of the mean patient satisfaction when $x_1 = 35$, $x_2 = 45$, and $x_3=2.2$ and interpret this interval in the context of the problem. 

```{r eval=FALSE}
?predict.lm

#new_obs <- data.frame(age=?, severity=?, anxiety=?)
#predict(?, ?, interval="?", level=?)
```


---
### Planning ahead for next class  

- Prepare for class next week 

  * Watch videos for Week 12 before class on Tuesday  
  
  * **Submit HW 7** by 8:00am (EST) on Tuesday (remember I only check Slack on Fridays and Mondays) 
  
  * **Finish Part 2** of your Final Project is due on Moodle by Monday at noon (EST)

- Regarding your final project and test 3

  * You will automatically lose 10 points for every day your submission is late 
  
  * No exceptions! 


---
### Announcements 

**Math/Stat Department Dresden Memorial Lecture by Professor Sarah Koch** 

Sarah Koch is an Associate Professor of Mathematics at the University of Michigan. Her research combines topology, algebraic geometry, and complex analysis in the field of complex dynamics, at once an ancient field asking basic questions about what happens when you repeat an operation over and over, and at the same time, a very modern one, whose beautiful Julia and Mandelbrot sets are illustrated on many a screensaver today.

.scroll-small[

**Friday, April 23, 3:00-4:00pm** Dresden Presentation and Q&A

Math Circles: a bundle of outreach
One of my favorite parts of being a mathematician is sharing math with other people. I have been extensively involved in outreach since I arrived at the Michigan Math Department in 2013. I have led Math Circle sessions for middle schoolers, high schoolers, and math teachers. In 2018, I was on my way to Dearborn, Michigan to lead a Math Circle session with one of my colleagues. Something happened during that trip that changed my life. I would love to tell you about it!

**Friday, April 23, 4:10-4:40pm** AWM/W+iMS Virtual Tea with Speaker
]

Zoom Link for Dresden Lecture/Presentation and Q&A https://swarthmore.zoom.us/j/92417771543 

This event will be recorded and posted on Math/Stat Dept. 2020-2021 Colloquium Schedule   